{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NetworkTest.ipynb","provenance":[],"authorship_tag":"ABX9TyNE5SNmX2uGNdSYnhvotd7v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"WBCYCgNqwd5l"},"source":["from __future__ import print_function\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","import time\n","\n","device = torch.device(\"cuda:0\")\n","\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5, 1)        \n","        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n","        self.fc1 = nn.Linear(4*4*50, 500)\n","        self.fc2 = nn.Linear(500, 10)\n","\n","\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = x.view(-1, 4*4*50)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","def train(log_interval, model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        #print(model.conv1.weight.data[0,0,1,1])\n","        loss.backward()\n","        #print(model.conv1.weight.data[0,0,1,1])\n","        optimizer.step()\n","\n","\n","\n","  \n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","def test( model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print(data.shape)\n","    for i in range(20):\n","        plt.imshow(data.cpu()[i,0,:,:])\n","        print(pred.cpu()[i])\n","        plt.show()\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","# Main code\n","print(\"running Code\")\n","batch_size=64\n","epochs=2\n","lr=0.01\n","momentum=0.5\n","no_cuda=False\n","seed=1\n","log_interval=1\n","\n","print(\"vars done\")\n","\n","use_cuda = not no_cuda and torch.cuda.is_available()\n","\n","torch.manual_seed(seed)\n","\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","print(\"data loading\")\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=1000, shuffle=True, **kwargs)\n","\n","\n","model = Net().to(device)\n","\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","print(\"Training\")\n","#optimizer=1\n","for epoch in range(1, epochs + 1):\n","    train(log_interval, model, device, train_loader, optimizer, epoch)\n","    \n","    \n","test(model, device, test_loader)\n","\n","print(\"Done\")\n","#print(model.conv1.weight)\n","#print(model.conv1.weight.shape)\n","#if (args.save_model):\n","#    torch.save(model.state_dict(),\"mnist_cnn.pt\")\n","\n"],"execution_count":null,"outputs":[]}]}