{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"authorship_tag":"ABX9TyP/qAPts0duSv9ej5oxXR57"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"hV2sbOGrTovg"},"source":["import torch\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import matplotlib\n","import config\n","import utils\n","from model import FaceKeypointResNet50\n","from dataset import train_data, train_loader, valid_data, valid_loader\n","from tqdm import tqdm\n","matplotlib.style.use('ggplot')\n","\n","# model \n","model = FaceKeypointResNet50(pretrained=True, requires_grad=True).to(config.DEVICE)\n","# optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config.LR)\n","# we need a loss function which is good for regression like SmmothL1Loss ...\n","# ... or MSELoss\n","criterion = nn.SmoothL1Loss()\n","\n","# training function\n","def fit(model, dataloader, data):\n","    print('Training')\n","    model.train()\n","    train_running_loss = 0.0\n","    counter = 0\n","    # calculate the number of batches\n","    num_batches = int(len(data)/dataloader.batch_size)\n","    for i, data in tqdm(enumerate(dataloader), total=num_batches):\n","        counter += 1\n","        image, keypoints = data['image'].to(config.DEVICE), data['keypoints'].to(config.DEVICE)\n","        # flatten the keypoints\n","        keypoints = keypoints.view(keypoints.size(0), -1)\n","        optimizer.zero_grad()\n","        outputs = model(image)\n","        loss = criterion(outputs, keypoints)\n","        train_running_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    train_loss = train_running_loss/counter\n","    return train_loss\n","\n","# validatioon function\n","def validate(model, dataloader, data, epoch):\n","    print('Validating')\n","    model.eval()\n","    valid_running_loss = 0.0\n","    counter = 0\n","    # calculate the number of batches\n","    num_batches = int(len(data)/dataloader.batch_size)\n","    with torch.no_grad():\n","        for i, data in tqdm(enumerate(dataloader), total=num_batches):\n","            counter += 1\n","            image, keypoints = data['image'].to(config.DEVICE), data['keypoints'].to(config.DEVICE)\n","            # flatten the keypoints\n","            keypoints = keypoints.view(keypoints.size(0), -1)\n","            outputs = model(image)\n","            loss = criterion(outputs, keypoints)\n","            valid_running_loss += loss.item()\n","            # plot the predicted validation keypoints after every...\n","            # ... predefined number of epochs\n","            if (epoch+1) % 1 == 0 and i == 0:\n","                utils.valid_keypoints_plot(image, outputs, keypoints, epoch)\n","        \n","    valid_loss = valid_running_loss/counter\n","    return valid_loss\n","\n","train_loss = []\n","val_loss = []\n","for epoch in range(config.EPOCHS):\n","    print(f\"Epoch {epoch+1} of {config.EPOCHS}\")\n","    train_epoch_loss = fit(model, train_loader, train_data)\n","    val_epoch_loss = validate(model, valid_loader, valid_data, epoch)\n","    train_loss.append(train_epoch_loss)\n","    val_loss.append(val_epoch_loss)\n","    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n","    print(f'Val Loss: {val_epoch_loss:.4f}')\n","\n","# loss plots\n","plt.figure(figsize=(10, 7))\n","plt.plot(train_loss, color='orange', label='train loss')\n","plt.plot(val_loss, color='red', label='validataion loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.savefig(f\"{config.OUTPUT_PATH}/loss.png\")\n","plt.show()\n","torch.save({\n","            'epoch': config.EPOCHS,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': criterion,\n","            }, f\"{config.OUTPUT_PATH}/model.pth\")\n","print('DONE TRAINING')\n"],"execution_count":null,"outputs":[]}]}